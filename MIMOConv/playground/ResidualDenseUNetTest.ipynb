{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:02:10.473930400Z",
     "start_time": "2024-04-04T03:02:10.329791600Z"
    }
   },
   "id": "749d6a40b02c2b05",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:02:11.466477300Z",
     "start_time": "2024-04-04T03:02:11.312728700Z"
    }
   },
   "id": "initial_id",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Assuming each folder contains the same number of corresponding images\n",
    "        self.image_names = os.listdir(os.path.join(root_dir, \"gaussian\"))  \n",
    "\n",
    "    def __len__(self):\n",
    "        # Each clean image corresponds to 4 noisy images (gaussian, salt-pepper, poisson, speckle)\n",
    "        return len(self.image_names)  \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = []\n",
    "        for noise_type in [\"gaussian\", \"salt-pepper\", \"poisson\", \"speckle\"]:\n",
    "            img_path = os.path.join(self.root_dir, noise_type, self.image_names[idx])\n",
    "            image = read_image(img_path).float() / 255.0  # Normalize to [0, 1]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            images.append(image)\n",
    "\n",
    "        # Load the corresponding clean image\n",
    "        clean_img_path = os.path.join(self.root_dir, \"clean\", self.image_names[idx])\n",
    "        clean_image = read_image(clean_img_path).float() / 255.0  # Normalize to [0, 1]\n",
    "        if self.transform:\n",
    "            clean_image = self.transform(clean_image)\n",
    "\n",
    "        return torch.stack(images), clean_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:02:12.017890Z",
     "start_time": "2024-04-04T03:02:11.854808400Z"
    }
   },
   "id": "c8c2efae3046703e",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(root_dir=\"../data/div2k-denoise\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:02:12.727439400Z",
     "start_time": "2024-04-04T03:02:12.539675800Z"
    }
   },
   "id": "4f0995b31fd35997",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# DataLoader to handle batching\n",
    "def custom_collate_fn(batch):\n",
    "    noisy_batch = [item[0] for item in batch]\n",
    "    clean_batch = [item[1] for item in batch]\n",
    "    \n",
    "    noisy_batch = torch.cat(noisy_batch, dim=0)\n",
    "    \n",
    "    clean_batch = torch.stack(clean_batch, dim=0)\n",
    "    clean_batch = clean_batch.repeat(4, 1, 1, 1)\n",
    "    \n",
    "    return noisy_batch, clean_batch  \n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=custom_collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:02:13.361739500Z",
     "start_time": "2024-04-04T03:02:13.204187700Z"
    }
   },
   "id": "7623cfb7818a582a",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def display_grayscale_tensor(tensor):\n",
    "\n",
    "    if tensor.dim() == 3 and tensor.shape[0] == 1:\n",
    "        # Remove the channel dimension and convert to numpy for display\n",
    "        image = tensor.squeeze().numpy()\n",
    "    elif tensor.dim() == 2:\n",
    "        image = tensor.numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Tensor must be of shape (1, H, W) or (H, W)\")\n",
    "\n",
    "    plt.imshow(image, cmap='gray') \n",
    "    plt.axis('off') \n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:02:13.919722900Z",
     "start_time": "2024-04-04T03:02:13.758681700Z"
    }
   },
   "id": "faf489550f81f379",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for noisy_batch, clean_batch in data_loader:\n",
    "#     for noisy_image in noisy_batch:\n",
    "#         print(noisy_image.shape)\n",
    "#         display_grayscale_tensor(noisy_image)\n",
    "#     for clean_image in clean_batch:\n",
    "#         print(clean_image.shape)\n",
    "#         display_grayscale_tensor(clean_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:02:14.504583Z",
     "start_time": "2024-04-04T03:02:14.330522200Z"
    }
   },
   "id": "a6c18d1d53303887",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "3384"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:59:25.808266500Z",
     "start_time": "2024-04-04T03:59:25.307516400Z"
    }
   },
   "id": "632c651206c3b23a",
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input torch.Size([8, 1, 256, 256])\n",
      "Conv 1 torch.Size([8, 64, 256, 256])\n",
      "Superposition Reshape torch.Size([2, 4, 64, 256, 256])\n",
      "Bind torch.Size([2, 64, 256, 256])\n",
      "Level 0 torch.Size([2, 64, 256, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_29916\\2914694487.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m         \u001B[1;31m# Forward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnoisy_imgs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[1;31m# Calculate loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\msc-env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PhD-LaTrobe\\multiple-input-multiple-output-nets\\MIMOConv\\src\\models\\residualdenseunet.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    210\u001B[0m         \u001B[0mout_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdown_0\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_0\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Level 1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m         \u001B[0mout_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblock_1_0\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 212\u001B[1;33m         \u001B[0mout_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblock_1_1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    213\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    214\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Level 1\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\msc-env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PhD-LaTrobe\\multiple-input-multiple-output-nets\\MIMOConv\\src\\models\\residualdenseunet.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    103\u001B[0m         \u001B[0mout_2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mout_1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 104\u001B[1;33m         \u001B[0mout_3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mactv_3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv_3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout_2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    105\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    106\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mout_3\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\msc-env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1188\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1191\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\msc-env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    462\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 463\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    464\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    465\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\msc-env\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    458\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m    459\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[1;32m--> 460\u001B[1;33m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[0;32m    461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    462\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from models.residualdenseunet import RDUNet\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = RDUNet(channels=64, base_filters=64).to(device)  # Adjust the parameters as needed\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25  # Define the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for noisy_imgs, clean_imgs in data_loader:\n",
    "        noisy_imgs = noisy_imgs.to(device)\n",
    "        clean_imgs = clean_imgs.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(noisy_imgs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, clean_imgs)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(data_loader)}')\n",
    "    \n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:59:21.912336800Z",
     "start_time": "2024-04-04T03:59:20.069359600Z"
    }
   },
   "id": "fa295e6f7868259f",
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T03:00:56.770751100Z",
     "start_time": "2024-04-04T03:00:56.761747400Z"
    }
   },
   "id": "eea8f8f273a5b3f5",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e8643d339c9af36b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
